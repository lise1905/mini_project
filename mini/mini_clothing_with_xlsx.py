# -*- coding: utf-8 -*-
"""mini_clothing with xlsx.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EvfoJz2t2EI6kqCHkKiJcI0IN7JzqNsQ
"""

import pandas as pd
from pandas import ExcelWriter
from pandas import ExcelFile
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/mini_project

data = pd.read_excel('dataset_cloth_recom.xlsx')

print(data.head(10))

data.dtypes

pip install surprise

from surprise import Dataset
from surprise import Reader
import os, io
from surprise import SVD
from surprise import accuracy

train, test = train_test_split(data, test_size=0.2)

def preprocessAge(data):
  bins = pd.IntervalIndex.from_tuples([(5, 15), (15, 30), (30, 50),(50,65),(65,100)])
  x = pd.cut(data['age'].to_list(), bins)
  x.categories = ['1','2','3','4','5']
  data['age_bins']  = x
  age_Preprocessed_data = data[~data['age_bins'].isnull()]
  # print ('{0} rows got dropped after age preprocessing'.format(str(data.shape[0] - age_Preprocessed_data.shape[0])))
  return age_Preprocessed_data

def preprocessBustsize(age_Preprocessed_data):
  data_bust_size_not_null = age_Preprocessed_data[~age_Preprocessed_data['bust size'].isnull()]
  data_bust_size_not_null['bust size'] = data_bust_size_not_null['bust size'].apply(lambda x : (int(x[:2]), x[2:]))
  data_bust_size_not_null.shape
  data_bust_size_not_null[['bust Size1', 'bust']] = pd.DataFrame(data_bust_size_not_null['bust size'].tolist(), index=data_bust_size_not_null.index)
  bustDict = {'a': 1, 'aa': 1, 'b': 2, 'c': 3, 'd': 4, 
            'd+': 5, 'dd': 5, 'ddd/e': 6,
           'f':7 , 'g': 8, 'h': 9, 'i': 10, 'j': 11}
  data_bust_size_not_null['bust1'] = data_bust_size_not_null['bust'].map(bustDict)
  # Calculating model of bust size based on age grp.
  def funct(df):
    return df.mode()
  x = data_bust_size_not_null[['age_bins','bust Size1','bust1']].groupby('age_bins').apply(funct)
  x.reset_index(inplace= True, drop = True)
  data_bust_size_null = age_Preprocessed_data[age_Preprocessed_data['bust size'].isnull()]
  data_bust_size_null = pd.merge(data_bust_size_null, x, how ='left', left_on = 'age_bins', right_on = 'age_bins')
  data_bust_size_cleansed = data_bust_size_not_null.append(data_bust_size_null)
  return data_bust_size_cleansed

def preprocessHeight(data_bust_size_cleansed):
  data_bust_size_cleansed['heightCM'] = data_bust_size_cleansed['height'].apply(lambda x : (int(x.split("\'")[0]) * 30.48) + (int(x.split("\'")[1][:-1]) * 2.54) 
                                                        if type(x) == str else x)
  data_bust_size_cleansed['heightCM'].fillna((data_bust_size_cleansed['heightCM'].mean()), inplace=True)
  return data_bust_size_cleansed

def preprocessWeight(data_bust_size_cleansed):
  data_bust_size_cleansed['weightLbs'] = data_bust_size_cleansed['weight'].apply(lambda x : int(x[:-3])                                                        if type(x) == str else x)
  data_bust_size_cleansed['weightLbs'].fillna((data_bust_size_cleansed['weightLbs'].mean()), inplace=True)
  return data_bust_size_cleansed

def preprocessRentedFor(data_bust_size_cleansed):
  data_bust_size_cleansed['rented for'].fillna('other', inplace=True)
  return data_bust_size_cleansed

def preprocessBodytype(data_bust_size_cleansed):
  # Calculating model of body type based on Bust Size.
  data_body_type_not_null = data_bust_size_cleansed[~data_bust_size_cleansed['body type'].isnull()]
  def func(df):
    return df.mode()
  x = data_body_type_not_null[['bust Size1','body type']].groupby('bust Size1').apply(func)
  x.reset_index(inplace= True, drop = True)
  # print(x)
  data_body_type_null = data_bust_size_cleansed[data_bust_size_cleansed['body type'].isnull()]
  data_body_type_null = pd.merge(data_body_type_null, x, how ='left', left_on = 'bust Size1', right_on = 'bust Size1')
  # print(data_body_type_null)
  data_body_type_cleansed = data_body_type_not_null.append(data_body_type_null,sort=True)
  # print(data_body_type_cleansed)
  data_body_type_cleansed['body type'].fillna(data_body_type_cleansed['body type_y'], inplace=True)
  del data_body_type_cleansed['body type_x']
  del data_body_type_cleansed['body type_y']
  return data_body_type_cleansed

def createFinalDataframe(cleansedData):
  final_df=cleansedData.copy()
  final_df=final_df.drop(['rented for','rating','category','age_bins','bust','bust size','fit','height','item_id','review_summary','user_id','weight','review_text'],axis=1)
  cleanup_nums = {"body type":     {"hourglass": 1, "straight & narrow": 2, "pear": 3,"athletic": 4, "full bust": 5,"petite": 6, "apple": 7}}
  final_df.replace(cleanup_nums, inplace=True)
  return final_df

def createFinalTestDataframe(cleansedData):
  final_df=cleansedData.copy()
  final_df=final_df.drop(['rating','category','age_bins','bust','bust size','fit','height','item_id','review_summary','weight','review_text'],axis=1)
  cleanup_nums = {"body type":     {"hourglass": 1, "straight & narrow": 2, "pear": 3,"athletic": 4, "full bust": 5,"petite": 6, "apple": 7}}
  final_df.replace(cleanup_nums, inplace=True)
  return final_df

age_Preprocessed_data=preprocessAge(train)
data_bust_size_cleansed=preprocessBustsize(age_Preprocessed_data)
data_bust_size_cleansed=preprocessHeight(data_bust_size_cleansed)
data_bust_size_cleansed=preprocessWeight(data_bust_size_cleansed)
data_bust_size_cleansed=preprocessRentedFor(data_bust_size_cleansed)
cleansedData=preprocessBodytype(data_bust_size_cleansed)
final_df=createFinalDataframe(cleansedData)

feature_names = ['age', 'bust Size1','bust1','size','heightCM','weightLbs']
X = final_df[feature_names]
y = final_df['body type']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

print(X)

print(y)

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, 
                               bootstrap = True,
                               max_features = 'sqrt')
model.fit(X_train, y_train)
#y_pred = model.predict(X_test)
#print(classification_report(y_test, y_pred))
print('Accuracy of Random forest classifier on training set: {:.2f}'
    .format(model.score(X_train, y_train)))
print('Accuracy of Random forest classifier on test set: {:.2f}'
     .format(model.score(X_test, y_test)))

'''
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred = logreg.predict(X_test)
print(classification_report(y_test, y_pred))
#print('Accuracy of Logistic regression classifier on training set: {:.2f}'
 #    .format(logreg.score(X_train, y_train)))
#print('Accuracy of Logistic regression classifier on test set: {:.2f}'
 #    .format(logreg.score(X_test, y_test)))
'''

'''
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred1 = knn.predict(X_test)
#print(confusion_matrix(y_test, y_pred1))
print(classification_report(y_test, y_pred1))
#print('Accuracy of K-NN classifier on training set: {:.2f}'
 #    .format(knn.score(X_train, y_train)))
#print('Accuracy of K-NN classifier on test set: {:.2f}'
 #    .format(knn.score(X_test, y_test)))
 '''

age_Preprocessed_testdata=preprocessAge(test)
testdata_bust_size_cleansed=preprocessBustsize(age_Preprocessed_testdata)
testdata_bust_size_cleansed=preprocessHeight(testdata_bust_size_cleansed)
testdata_bust_size_cleansed=preprocessWeight(testdata_bust_size_cleansed)
testdata_bust_size_cleansed=preprocessRentedFor(testdata_bust_size_cleansed)
cleansedTestData=preprocessBodytype(testdata_bust_size_cleansed)
final_test_df=createFinalTestDataframe(cleansedTestData)

feature_names = ['age', 'bust Size1','bust1','size','heightCM','weightLbs','rented for','user_id']
testdata = final_test_df[feature_names]

for col in testdata.columns:
    print(col)

print(testdata)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

#%cd ..

#ls

#cf_df=[]
for i in range(1):#len(testdata)
    age = testdata.iloc[i,0]
    bustSize1 = testdata.iloc[i,1]
    bust1 = testdata.iloc[i,2]
    size = testdata.iloc[i,3]
    heightCM = testdata.iloc[i,4]
    weightLbs = testdata.iloc[i,5]
    
    xnew=[[age,bustSize1,bust1,size,heightCM,weightLbs]]
    bodytypenumber=model.predict(xnew)
    #print("Predicted body type:",bodytypenumber)
    
    bodytypearray=["NaN","hourglass", "straight & narrow", "pear","athletic", "full bust","petite", "apple"]
    bodytype=np.asanyarray(bodytypearray)[bodytypenumber]
    print("Predicted body type:",bodytype)
    
    cluster_df=cleansedData.copy()
    groupedbybodytype = cluster_df.groupby('body type')
    for name,group in groupedbybodytype:
      if(bodytype==name):
        #print(name)
        #print(group)
        grouped_df=group.copy()
    rentedFor=testdata.iloc[i,6]
    
    groupedbybodytype = grouped_df.groupby('rented for')
    for name,group in groupedbybodytype:
      if(rentedFor==name):
        #print(name)
        #print(group)
        cf_df=group.copy()
    cf_df=cf_df[['user_id','item_id','rating']].copy()
    
    
    reader = Reader(rating_scale=(1,10))
    traindata=Dataset.load_from_df(cf_df,reader)
    trainingSet = traindata.build_full_trainset()
    
    svdAlgo = SVD(n_factors=200,n_epochs=50)
    svdAlgo.fit(trainingSet)
    
    itemid=cf_df['item_id'].unique()
    ratingOutput = pd.DataFrame(columns=['item_id', 'rating']) #Create a blank df with 2 columns at first and then append data
    
    for i in range(len(itemid)):
        user=cf_df.iloc[i,0] #User_id
        item=cf_df.iloc[i,1] #Item_id
        output=svdAlgo.predict(user,item,r_ui=None,clip=True,verbose=False)
        ratingOutput = ratingOutput.append({'item_id': item, 'rating': output.est}, ignore_index=True)
        
    ratingOutput=ratingOutput.sort_values('rating',ascending=False)
    outputdf=ratingOutput.head(10).copy()
    #print("Top 10 recommended items with their predicted ratings:")
    #outputdf.head()
    rawdf = pd.read_excel("dataset_cloth_recom.xlsx")
    itemID=outputdf['item_id'].iloc[0]#.astype('int64')
    print("Recommended itemID:",itemID)
    finaldf = (rawdf[rawdf['item_id']==itemID].iloc[0])
    print("Recommended category:",finaldf['category'])
    finalpro = (rawdf[rawdf['item_id']==itemID].iloc[0])
    print("Recommended product:",finaldf['product'])
    print("Occasion:",finaldf['rented for'])
    plt.imshow(mpimg.imread(finaldf['product']))

import pickle
with open('model.pkl','wb') as file:
  pickle.dump(model,file)

import pickle
with open('svd.pkl','wb') as file:
  pickle.dump(svdAlgo,file)

#from zipfile import ZipFile
#file_name = "/content/dresszip"

#with ZipFile(file_name, 'r') as zip:
 # zip.extractall()
  #print('Done')